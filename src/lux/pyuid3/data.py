# AUTOGENERATED! DO NOT EDIT! File to edit: src/data.ipynb (unless otherwise specified).

__all__ = ['Data']

# Cell
import warnings
import pandas as pd
import numpy as np
from pandas import DataFrame
from typing import List, Set, Dict
from typing import Tuple
from collections import OrderedDict

from .parse_exception import ParseException
from .att_stats import AttStats
from .attribute import Attribute


# Cell
class Data:

    def __init__(self, name: str = None, attributes: List[Dict] = None, instances: List[Dict] = None):
        """ 
        Initialize a Data object.

        Parameters:
        -----------
        :param name: str, optional
            The name of the dataset.
        :param attributes: List[Dict], optional
            List of attribute Dict defining the dataset's attributes.
        :param instances: List[Dict], optional
            List of instance Dict containing the dataset's instances.
        """
        self.name = name
        self.instances = instances
        self.attributes = OrderedDict()
        self.expected_values = dict()
        self.class_attribute_name = None

        for at in attributes:
            self.attributes[at['name']]=at
            
        if len(attributes) > 0:
            self.class_attribute_name = attributes[-1]['name']

        self.__df__=None
        
    def __len__(self):
        """
        Returns the number of instances in the dataset.

        Returns:
        --------
        :return: int
            The number of instances in the dataset.
        """
        return len(self.instances)

    def filter_nominal_attribute_value(self, at: Dict, value: str, copy : bool =False) -> 'Data':
        """ Filter the dataset based on the given nominal attribute value.

        Parameters:
        -----------
        :param at: Dict
            The attribute Dict to filter.
        :param value: str
            The value to filter.
        :param copy: bool, optional
            Whether to create a copy of the filtered dataset. Defaults to False.

        Returns:
        --------
        :return: Data
            The filtered dataset.
        """
        new_instances = []
        new_attributes = self.get_attributes().copy()

        for i in self.instances:
            reading = i.get_reading_for_attribute(at.get_name())
            instance_val = reading.get_most_probable().get_name()
            if str(instance_val) == str(value):
                if copy:
                    new_instance = {'readings': i['readings'].copy()}
                else:
                    new_instance = i
                new_instances.append(new_instance)

        return Data(self.name, new_attributes, new_instances)

    def filter_numeric_attribute_value(self, at: Dict, value: str, copy : bool = False )-> Tuple['Data','Data']:
        """ Filter the dataset based on the given numeric attribute value.

       Parameters:
       -----------
       :param at: Dict
           The attribute Dict to filter.
       :param value: str
           The value to filter.
       :param copy: bool, optional
           Whether to create a copy of the filtered dataset. Defaults to False.

       Returns:
       --------
       :return: Tuple[Data, Data]
           A tuple containing two filtered datasets:
           - The first dataset contains instances where the attribute value is less than the given value.
           - The second dataset contains instances where the attribute value is greater than or equal to the given value.
       """
        new_instances_less_than = []
        new_instances_greater_equal = []
        new_attributes_lt = self.get_attributes().copy()
        new_attributes_gt = self.get_attributes().copy()
        value = float(value)
        for i in self.instances:
            reading = i['readings'][at['name']]
            instance_val = reading['most_probable']['name']
            if copy:
                new_instance = i.copy()
            else:
                new_instance = i
                
            if float(instance_val) < value:
                new_instances_less_than.append(new_instance) 
            else:
                new_instances_greater_equal.append(new_instance)

        return (Data(self.name, new_attributes_lt, new_instances_less_than),Data(self.name, new_attributes_gt, new_instances_greater_equal))
    
    def filter_numeric_attribute_value_expr(self, at: Dict, expr: str, copy : bool = False)-> Tuple['Data','Data']:
        """ Filter the dataset based on the given expression involving a numeric attribute value.

        Parameters:
        -----------
        :param at: Dict
            The attribute Dict to filter.
        :param expr: str
            The expression to evaluate. It can involve comparisons and arithmetic operations with the attribute value.
        :param copy: bool, optional
            Whether to create a copy of the filtered dataset. Defaults to False.

        Returns:
        --------
        :return: Tuple[Data, Data]
            A tuple containing two filtered datasets:
            - The first dataset contains instances where the attribute value satisfies the expression.
            - The second dataset contains instances where the attribute value does not satisfy the expression.
        """
        new_instances_less_than = []
        new_instances_greater_equal = []
        new_attributes_lt = self.get_attributes().copy()
        new_attributes_gt = self.get_attributes().copy()
        
        for i in self.instances:
            reading = i['readings'][at['name']]
            instance_val = reading['most_probable']['name']
            if copy:
                new_instance = i.copy()
            else:
                new_instance = i
                
            readings = i['readings']
            expr2eval = expr
            for key in sorted(readings.keys(),key=len,reverse=True):
                expr2eval = expr2eval.replace(key, readings[key]['most_probable']['name'])

            if eval(f'{instance_val} < {expr2eval}'):
                new_instances_less_than.append(new_instance) 
            else:
                new_instances_greater_equal.append(new_instance)

        return (Data(self.name, new_attributes_lt, new_instances_less_than),Data(self.name, new_attributes_gt, new_instances_greater_equal))
    

    def get_attribute_of_name(self, att_name: str) -> Dict:
        """ Get the attribute Dict corresponding to the given attribute name.

        Parameters:
        -----------
        :param att_name: str
            The name of the attribute to retrieve.

        Returns:
        --------
        :return: Dict
            The attribute Dict corresponding to the given attribute name.
            Returns None if the attribute name is not found in the dataset.
        """
        return self.attributes.get(att_name, None)

    def to_dataframe(self,most_probable=True) -> pd.DataFrame:
        """ Convert the dataset to a pandas DataFrame.

        Parameters:
        -----------
        :param most_probable: bool, optional (default=True)
            Whether to use the most probable values for each attribute. 
            In current version there is no other option than True.

        Returns:
        --------
        :return: pd.DataFrame
            A pandas DataFrame representing the dataset.
        """
        if self.__df__ is not None:
            return self.__df__
        columns = [at['name'] for at in self.get_attributes()]
        values = []
        for i in self.instances:
            row =[]
            for att in columns:
                ar = i['readings'][att]
                if self.get_attribute_of_name(att)['type'] == Attribute.TYPE_NOMINAL:
                    single_value = int(float(ar['most_probable']['name']))
                elif self.get_attribute_of_name(att)['type'] == Attribute.TYPE_NUMERICAL:
                    single_value = float(ar['most_probable']['name'])
                row.append(single_value)
            values.append(row)

        self.__df__ = pd.DataFrame(values, columns=columns)
        return self.__df__

    def to_dataframe_importances(self, average_absolute=False):
        """ Convert the dataset's importances to a pandas DataFrame.

        Parameters:
        -----------
        :param average_absolute: bool, optional (default=False)
            Whether to calculate the average absolute importances.

        Returns:
        --------
        :return: pd.DataFrame
            A pandas DataFrame representing the importances of each attribute.
        """
        columns = [at['name'] for at in self.get_attributes() if at['name'] != self.class_attribute_name]
        values = []
        for i in self.instances:
            row =[]
            for att in columns:
                ar = i['readings'][att]
                importances = list(ar['most_probable']['importances'].values())
                row.append(importances)
            values.append(row)

        result = np.array([sv for sv in np.moveaxis(np.array(values), 2,0)])
        if average_absolute:
            return np.abs(result).mean(1).mean(0)
        else:
            return result

    def calculate_statistics(self, att: Dict) -> AttStats:
        """ Calculate statistics for a specific attribute in the dataset.

        Parameters:
        -----------
        :param att: Dict
            The attribute Dict for which statistics are to be calculated.

        Returns:
        --------
        :return: AttStats
            An object containing statistics for the specified attribute.
        """
        return AttStats.calculate_statistics(att, self)

    def set_importances(self, importances: pd.DataFrame, expected_values: Dict) -> 'Data':
        """ Set importances for each attribute based on the provided DataFrame of importances and expected values.

        Parameters:
        -----------
        :param importances: pd.DataFrame
            DataFrame containing importances for each attribute.
        :param expected_values: Dict
            Dictionary containing expected values.

        Returns:
        --------
        :return: Data
            A new Data object with updated importances.
        """
        new_instances = []
        if type(importances.columns) is pd.MultiIndex:
            classes = list(importances.columns.get_level_values(0).unique())
        else:
            importances=pd.DataFrame({'__all__':importances})
            warnings.warn("WARNING: SHAP values passed for one class only. This may lead to unexpected behaviour.")

        names = list(importances.columns.get_level_values(1).unique())
        self.expected_values = expected_values
        for row, instance in zip(importances.to_numpy(), self.instances):
            new_instance = instance.copy()
            new_readings = instance['readings']
            for i, att in enumerate(names):
                reading = new_readings[att]
                importance_dict = {}
                for j, cl in enumerate(classes):
                    importance_dict[cl] = row[j * len(names) + i]
                new_values = reading['values']
                for v in new_values:
                    v['importances'] = importance_dict
            new_instances.append(new_instance)

        return Data(self.name, self.get_attributes().copy(), new_instances)

    def reduce_importance_for_attribute(self, att: Dict, discount_factor: float, for_class : str = None) -> 'Data':
        """ Reduce the importance of a specific attribute by a given discount factor.

        Parameters:
        -----------
        :param att: Dict
            The attribute Dict for which importance needs to be reduced.
        :param discount_factor: float
            The discount factor by which to reduce the importance.
        :param for_class: str, optional (default=None)
            If provided, reduce the importance only for the specified class.

        Returns:
        --------
        :return: Data
            A new Data object with reduced importance for the specified attribute.
        """
        new_instances = []
        for i in self.instances:
            new_instance = i.copy()
            new_readings = new_readings['readings'][att['name']]
            new_values = new_readings['values']
            if for_class is None:
                for v in new_values:
                    v['importances'] = {key: value * (1-discount_factor) for key, value in v['importances'].items()}
            else:
                for v in new_values:
                    v['importances'] = {key: value * (1-discount_factor) for key, value in v['importances'].items() if key == for_class}

            new_instances.append(new_instance)

        return Data(self.name, self.get_attributes().copy(), new_instances)

    @staticmethod
    def __read_from_dataframe(df: pd.DataFrame, importances: pd.DataFrame=None, name: str="uarff_data", categorical:List[bool]=None) -> 'Data':
        """ Convert pandas Dataframe with importances to Data

        Parameters:
        -----------
        :param df: pd.Dataframe
            Pandas Dataframe with attribute values
        :param importances: pd.Dataframe, optional (default=None)
            Pandas Dataframe with importances associated to values.
            If not provided importances are set to 1 for each value 
        :param name: str, optional (default="uarff_data")
            Name of the resulting Data object
        :param categorical: List[bool], optional (default=None)
            List that specifies which of DataFrame columns are categorical
            If not provided every column except result is classed as numerical

        Returns:
        --------
        :return: Data
            A new Data object with values loaded from provided DataFrames
        """
        atts = []
        cols = df.columns
        if categorical is None:
            categorical = [False] * len(cols)
        if 'class' in df.columns:
            categorical[-1] = True

        for i, col in enumerate(cols):
            records = pd.unique(df[col])
            type = Attribute.TYPE_NUMERICAL
            domain = set()
            if categorical[i]:
                df = df.astype({col : str})
                type = Attribute.TYPE_NOMINAL
                domain = set(records.astype(str))

            atts.append({'name':col, 'domain':domain, 'type':type, 'value_to_split_on': '', 'info_gain':0.0 })

        if importances is not None:
            importances = importances.to_numpy()
        else:
            importances = np.ones(df.shape)

        insts = np.empty(df.shape[0], dict)
            
        idx = 0

        for x_i, ximp_i in zip(df.to_numpy(), importances):
            insts[idx] = {'readings': {}}
            for att, x_ij, ximp_xij in zip(atts, x_i, ximp_i):
                if att['type'] == Attribute.TYPE_NUMERICAL:
                    v = [{'name':str(x_ij), 'confidence': ximp_xij, 'importances' : {'Value' : 1}}]
                    reading = {'base_att': att, 'values':v, 'most_probable': v[0]}
                    insts[idx]['readings'][reading['base_att']['name']] = reading
                else:
                    v = [{'name':str(x_ij), 'confidence': ximp_xij, 'importances' : {'Value' : 1}}]
                    remaining = att['domain'].copy()
                    remaining.remove(x_ij)
                    uniform_prob = (1 - ximp_xij) / len(remaining)
                    for rv in remaining:
                        v.append({'name':str(rv), 'confidence': uniform_prob, 'importances' : {'Value' : 1}})
                    confidence = [value['confidence'] for value in v]
                    highest_conf = max(confidence)
                    index = confidence.index(highest_conf)
                    reading = {'base_att': att, 'values':v, 'most_probable': v[index]}
                    insts[idx]['readings'][reading['base_att']['name']] = reading
            idx += 1

        tmp_data = Data(name, atts, insts)
        tmp_data.update_attribute_domains()
        return tmp_data

    def update_attribute_domains(self):
        """ 
        Set attribute domains for numerical values
        """
        self.__df__ = None
        for a in self.get_attributes():
            if a['type'] == Attribute.TYPE_NUMERICAL:
                domain = self.__get_domain_from_data(a)
                a['domain'] = domain

    def __get_domain_from_data(self, a: Dict) -> Set[str]:
        """ 
        Get attribute domains for specific attribute from all gathered Data

        Parameters:
        -----------
        :param a: Dict
            The attribute Dict for which domain needs to be found.
            
        Returns:
        --------
        :return: Set[str]
            A set of values representing domain of given attribute
        """
        domain = set()
        for i in self.instances:
            value = i['readings'][a['name']]['most_probable']['name']
            domain.add(value)
        return domain

    @staticmethod
    def parse_ucsv(filename: str) -> 'Data':
        """ 
        Parse DataFrame from csv to Data object
        """
        df = pd.read_csv(filename)
        name = filename.split('/')[-1].split('.csv')[0]
        return Data.__read_from_dataframe(df, name=name)

    @staticmethod
    def parse_dataframe(df: pd.DataFrame, df_imps=None, name='uarff_data',categorical:List[bool]=None) -> 'Data':
        """ 
        Parse pd.DataFrame to Data object
        """
        return Data.__read_from_dataframe(df, df_imps, name, categorical)

    def get_instances(self) -> List[Dict]:
        return self.instances

    def get_attributes(self) -> List[Dict]:
        return list(self.attributes.values())

    def get_name(self) -> str:
        return self.name

    def get_class_attribute(self) -> Dict:
        return self.attributes[self.class_attribute_name]  # get last element
