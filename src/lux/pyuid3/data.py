# AUTOGENERATED! DO NOT EDIT! File to edit: src/data.ipynb (unless otherwise specified).

__all__ = ['Data']

# Cell
from io import TextIOWrapper, StringIO
import traceback
import re
import warnings
import pandas as pd
import numpy as np
from pandas import DataFrame
from typing import List, Set, Dict
from typing import Tuple
from collections import OrderedDict

from .parse_exception import ParseException
from .att_stats import AttStats
from .attribute import Attribute


# Cell
class Data:
    REAL_DOMAIN = '@REAL'

    def __init__(self, name: str = None, attributes: List[Dict] = None, instances: List[Dict] = None):
        """ Initialize a Data object.

                Parameters:
                -----------
                :param name: str, optional
                    The name of the dataset.
                :param attributes: List[Attribute], optional
                    List of attribute objects defining the dataset's attributes.
                :param instances: List[Instance], optional
                    List of instance objects containing the dataset's instances.
        """
        self.name = name
        self.instances = instances
        self.attributes = OrderedDict()
        self.expected_values = dict()
        for at in attributes:
            self.attributes[at['name']]=at
            
        if len(attributes) > 0:
            self.class_attribute_name = attributes[-1]['name']
        else:
            self.class_attribute_name = None
        self.__df__=None
        
    def __len__(self):
        """
        Returns the number of instances in the dataset.

        Returns:
        --------
        :return: int
            The number of instances in the dataset.
        """
        return len(self.instances)

    def filter_nominal_attribute_value(self, at: Attribute, value: str, copy : bool =False) -> 'Data':
        """ Filter the dataset based on the given nominal attribute value.

        Parameters:
        -----------
        :param at: Attribute
            The attribute to filter.
        :param value: str
            The value to filter.
        :param copy: bool, optional
            Whether to create a copy of the filtered dataset. Defaults to False.

        Returns:
        --------
        :return: Data
            The filtered dataset.
        """
        new_instances = []
        new_attributes = self.get_attributes().copy()

        for i in self.instances:
            reading = i.get_reading_for_attribute(at.get_name())
            instance_val = reading.get_most_probable().get_name()
            if str(instance_val) == str(value):
                if copy:
                    new_instance = {'readings': i['readings'].copy()}
                else:
                    new_instance = i
                new_instances.append(new_instance)

        return Data(self.name, new_attributes, new_instances)

    def filter_numeric_attribute_value(self, at: Attribute, value: str, copy : bool = False )-> Tuple['Data','Data']:
        """ Filter the dataset based on the given numeric attribute value.

       Parameters:
       -----------
       :param at: Attribute
           The attribute to filter.
       :param value: str
           The value to filter.
       :param copy: bool, optional
           Whether to create a copy of the filtered dataset. Defaults to False.

       Returns:
       --------
       :return: Tuple[Data, Data]
           A tuple containing two filtered datasets:
           - The first dataset contains instances where the attribute value is less than the given value.
           - The second dataset contains instances where the attribute value is greater than or equal to the given value.
       """
        new_instances_less_than = []
        new_instances_greater_equal = []
        new_attributes_lt = self.get_attributes().copy()
        new_attributes_gt = self.get_attributes().copy()
        value = float(value)
        for i in self.instances:
            reading = i['readings'][at['name']]
            instance_val = reading['most_probable']['name']
            if copy:
                new_instance = {'readings': i['readings'].copy()}
            else:
                new_instance = i
                
            if float(instance_val) < value:
                new_instances_less_than.append(new_instance) 
            else:
                new_instances_greater_equal.append(new_instance)

        return (Data(self.name, new_attributes_lt, new_instances_less_than),Data(self.name, new_attributes_gt, new_instances_greater_equal))
    
    def filter_numeric_attribute_value_expr(self, at: Attribute, expr: str, copy : bool = False )-> Tuple['Data','Data']:
        """ Filter the dataset based on the given expression involving a numeric attribute value.

        Parameters:
        -----------
        :param at: Attribute
            The attribute to filter.
        :param expr: str
            The expression to evaluate. It can involve comparisons and arithmetic operations with the attribute value.
        :param copy: bool, optional
            Whether to create a copy of the filtered dataset. Defaults to False.

        Returns:
        --------
        :return: Tuple[Data, Data]
            A tuple containing two filtered datasets:
            - The first dataset contains instances where the attribute value satisfies the expression.
            - The second dataset contains instances where the attribute value does not satisfy the expression.
        """
        new_instances_less_than = []
        new_instances_greater_equal = []
        new_attributes_lt = self.get_attributes().copy()
        new_attributes_gt = self.get_attributes().copy()
        
        for i in self.instances:
            reading = i['readings'][at['name']]
            instance_val = reading['most_probable']['name']
            if copy:
                new_instance = {'readings': i['readings'].copy()}
            else:
                new_instance = i
                
            readings = i['readings']
            expr2eval = expr
            for key in sorted(readings.keys(),key=len,reverse=True):
                expr2eval = expr2eval.replace(key, readings[key]['most_probable']['name'])

            if eval(f'{instance_val} < {expr2eval}'):
                new_instances_less_than.append(new_instance) 
            else:
                new_instances_greater_equal.append(new_instance)

        return (Data(self.name, new_attributes_lt, new_instances_less_than),Data(self.name, new_attributes_gt, new_instances_greater_equal))
    

    def get_attribute_of_name(self, att_name: str) -> Attribute:
        """ Get the attribute object corresponding to the given attribute name.

        Parameters:
        -----------
        :param att_name: str
            The name of the attribute to retrieve.

        Returns:
        --------
        :return: Attribute
            The attribute object corresponding to the given attribute name.
            Returns None if the attribute name is not found in the dataset.
        """
        return self.attributes.get(att_name, None)

    def to_dataframe(self,most_probable=True) -> pd.DataFrame:
        """ Convert the dataset to a pandas DataFrame.

        Parameters:
        -----------
        :param most_probable: bool, optional (default=True)
            Whether to use the most probable values for each attribute. In current version there is no other option than True.

        Returns:
        --------
        :return: pd.DataFrame
            A pandas DataFrame representing the dataset.
        """
        if self.__df__ is not None:
            return self.__df__
        columns = [at['name'] for at in self.get_attributes()]
        values = []
        for i in self.instances:
            row =[]
            for att in columns:
                ar = i['readings'][att]
                if self.get_attribute_of_name(att)['type'] == Attribute.TYPE_NOMINAL:
                    single_value = int(float(ar['most_probable']['name']))
                elif self.get_attribute_of_name(att)['type'] == Attribute.TYPE_NUMERICAL:
                    single_value = float(ar['most_probable']['name'])
                row.append(single_value)
            values.append(row)

        self.__df__ = pd.DataFrame(values, columns=columns)
        return self.__df__

    def to_dataframe_importances(self, average_absolute=False):
        """ Convert the dataset's importances to a pandas DataFrame.

        Parameters:
        -----------
        :param average_absolute: bool, optional (default=False)
            Whether to calculate the average absolute importances.

        Returns:
        --------
        :return: pd.DataFrame
            A pandas DataFrame representing the importances of each attribute.
        """
        columns = [at['name'] for at in self.get_attributes() if at['name'] != self.class_attribute_name]
        values = []
        for i in self.instances:
            row =[]
            for att in columns:
                ar = i['readings'][att]
                importances = list(ar['most_probable']['importances'].values())
                row.append(importances)
            values.append(row)

        result = np.array([sv for sv in np.moveaxis(np.array(values), 2,0)])
        if average_absolute:
            return np.abs(result).mean(1).mean(0)
        else:
            return result

    def calculate_statistics(self, att: Dict) -> AttStats:
        """ Calculate statistics for a specific attribute in the dataset.

        Parameters:
        -----------
        :param att: Attribute
            The attribute for which statistics are to be calculated.

        Returns:
        --------
        :return: AttStats
            An object containing statistics for the specified attribute.
        """
        return AttStats.calculate_statistics(att, self)

    def set_importances(self, importances: pd.DataFrame, expected_values: Dict) -> 'Data':
        """ Set importances for each attribute based on the provided DataFrame of importances and expected values.

        Parameters:
        -----------
        :param importances: pd.DataFrame
            DataFrame containing importances for each attribute.
        :param expected_values: Dict
            Dictionary containing expected values.

        Returns:
        --------
        :return: Data
            A new Data object with updated importances.
        """
        new_instances = []
        if type(importances.columns) is pd.MultiIndex:
            classes = list(importances.columns.get_level_values(0).unique())
        else:
            importances=pd.DataFrame({'__all__':importances})
            warnings.warn("WARNING: SHAP values passed for one class only. This may lead to unexpected behaviour.")

        self.expected_values = expected_values
        for (_,r),instance in zip(importances.iterrows(), self.instances):
            new_instance = instance.copy()
            new_readings = instance['readings']
            for att in r.index.get_level_values(1).unique():
                reading = new_readings[att]
                importance_dict = {}
                for cl in classes:
                    importance_dict[cl] = r[cl][att]
                new_values = reading['values']
                for v in new_values:
                    v['importances'] = importance_dict
            new_instances.append(new_instance)

        return Data(self.name, self.get_attributes().copy(), new_instances)

    def reduce_importance_for_attribute(self, att: Attribute, discount_factor: float, for_class : str = None) -> 'Data':
        """ Reduce the importance of a specific attribute by a given discount factor.

        Parameters:
        -----------
        :param att: Attribute
            The attribute for which importance needs to be reduced.
        :param discount_factor: float
            The discount factor by which to reduce the importance.
        :param for_class: str, optional (default=None)
            If provided, reduce the importance only for the specified class.

        Returns:
        --------
        :return: Data
            A new Data object with reduced importance for the specified attribute.
        """
        new_instances = []
        for i in self.instances:
            new_instance = i.copy()
            new_readings = new_readings['readings'][att['name']]
            new_values = new_readings['values']
            if for_class is None:
                for v in new_values:
                    v['importances'] = {key: value * (1-discount_factor) for key, value in v['importances'].items()}
            else:
                for v in new_values:
                    v['importances'] = {key: value * (1-discount_factor) for key, value in v['importances'].items() if key == for_class}

            new_instances.append(new_instance)

        return Data(self.name, self.get_attributes().copy(), new_instances)

    @staticmethod
    def __read_ucsv_from_dataframe(df: DataFrame, importances: DataFrame, name: str, categorical:List[bool]=None) -> 'Data':
        
        atts = []
        cols = df.columns
        if categorical is None:
            categorical = [False] * len(cols)
        if 'class' in df.columns:
            categorical[-1] = True

        for i, col in enumerate(cols):
            records = pd.unique(df[col])
            type = Attribute.TYPE_NUMERICAL
            domain = set()
            if categorical[i]:
                df = df.astype({col : str})
                type = Attribute.TYPE_NOMINAL
                domain = set(records.astype(str))

            atts.append({'name':col, 'domain':domain, 'type':type, 'value_to_split_on': '', 'info_gain':0.0 })

        if importances is not None:
            importances = importances.to_numpy()
        else:
            importances = np.ones(df.shape)

        insts = np.empty(df.shape[0], dict)
            
        idx = 0

        for x_i, ximp_i in zip(df.to_numpy(), importances):
            insts[idx] = {'readings': {}}
            for att, x_ij, ximp_xij in zip(atts, x_i, ximp_i):
                if att['type'] == Attribute.TYPE_NUMERICAL:
                    v = [{'name':str(x_ij), 'confidence': ximp_xij, 'importances' : {'Value' : 1}}]
                    reading = {'base_att': att, 'values':v, 'most_probable': v[0]}
                    insts[idx]['readings'][reading['base_att']['name']] = reading
                else:
                    v = [{'name':str(x_ij), 'confidence': ximp_xij, 'importances' : {'Value' : 1}}]
                    remaining = att['domain'].copy()
                    remaining.remove(x_ij)
                    uniform_prob = (1 - ximp_xij) / len(remaining)
                    for rv in remaining:
                        v.append({'name':str(rv), 'confidence': uniform_prob, 'importances' : {'Value' : 1}})
                    confidence = [value['confidence'] for value in v]
                    highest_conf = max(confidence)
                    index = confidence.index(highest_conf)
                    reading = {'base_att': att, 'values':v, 'most_probable': v[index]}
                    insts[idx]['readings'][reading['base_att']['name']] = reading
            idx += 1

        tmp_data = Data(name, atts, insts)
        tmp_data.update_attribute_domains()
        return tmp_data

    def update_attribute_domains(self):
        self.__df__ = None
        for a in self.get_attributes():
            if a['type'] == Attribute.TYPE_NUMERICAL:
                domain = self.__get_domain_from_data(a, self.instances)
                a['domain'] = domain

    def __get_domain_from_data(self, a: Dict, instances: List[Dict]) -> Set[str]:
        domain = set()
        for i in instances:
            value = i['readings'][a['name']]['most_probable']['name']
            domain.add(value)
        return domain

    @staticmethod
    def parse_ucsv(filename: str) -> 'Data':
        df = pd.read_csv(filename)
        name = filename.split('/')[-1].split('.csv')[0]
        out = Data.__read_ucsv_from_dataframe(df, None, name)
        return out

    @staticmethod
    def parse_dataframe(df: pd.DataFrame, df_imps = None, name='uarff_data',categorical:List[bool]=None) -> 'Data':
        out = Data.__read_ucsv_from_dataframe(df, df_imps, name, categorical)
        return out

    def get_instances(self) -> List[Dict]:
        return self.instances

    def get_attributes(self) -> List[Dict]:
        return list(self.attributes.values())

    def get_name(self) -> str:
        return self.name

    def get_class_attribute(self) -> Dict:
        return self.attributes[self.class_attribute_name]  # get last element
